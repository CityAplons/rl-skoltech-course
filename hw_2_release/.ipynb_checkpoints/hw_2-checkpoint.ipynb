{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"skoltech_logo.png\" alt=\"Skoltech\" width=80% height=60% style=\"padding-right:80px;\"/>\n",
    "<h1 style=\"color:#333333; text-align:center; line-height: 0;\">Reinforcement Learning</h1>\n",
    "<h5 style=\"color:#333333; text-align:center;\">Course MA030422</h5>\n",
    "\n",
    "<h2 style=\"color:#A7BD3F;\">Homework 2</h2>\n",
    "\n",
    "***\n",
    "\n",
    "### Intro\n",
    "\n",
    "#### First, a recap of homework 1\n",
    "\n",
    "In homework 1 we applied value iteration and policy iteration to an environment with discrete state and action spaces (aka a finite MDP). If you recall, the environment we used (FrozenLake 4x4) had 16 states and 4 actions. \n",
    "\n",
    "#### The algorithms from hw 1 have several characteristics:\n",
    "* The tabular representations of MDP variables had to be stored in memory:\n",
    "    * In the case of VI, the values of states, transitions, and rewards were stored in memory and referenced when calculating the best action to take\n",
    "    * In the case of PI, policy was additionally stored in memory.\n",
    "* Neither value nor policy functions were represented mathematically/analytically\n",
    "* Both value iteration (VI) and policy iteration (PI) were *repeatedly and reliably* able to solve the environment (when `is_slippery==False`)\n",
    "\n",
    "#### The problem with *Exact Value Iteration* and *Exact Policy Iteration*\n",
    "\n",
    "The problem with VI and PI from homework 1 is that when MDP variables (states, actions, transitions, or rewards) \"have a very large or infinite number of possible values (e.g., when they are continuous)\", then Tabular/stored \"representations are no longer possible, and value functions and policies need to be represented approximately\" <sup>[2]</sup>.\n",
    "\n",
    "Let's examine this issue in more specific terms. Examine the following VI algorithm <sup>[1]</sup>:\n",
    "\n",
    "<img src=\"vi.png\" width=\"70%\" height=\"70%\" />\n",
    "\n",
    "This algorithm is nearly identical to VI from hw 1. What problems/deficiencies can you identify in this algorithm if we had to scale it by 30 orders of magnitude? \n",
    "\n",
    "At least 5 problems/deficiencies come to mind with regard to scale <sup>[1]</sup>:\n",
    "1. All of the states are iterated over (line 3)\n",
    "2. Value of state $V(s)$ is stored for every state (line 5)\n",
    "3. Policy $\\pi$ is stored for every state (line 6)\n",
    "4. The expected return over future states ($s^\\prime$) is calculated recursively for all $s^\\prime$ (lines 5 and 6)\n",
    "5. Maximization is performed over all possible actions (lines 5 and 6)\n",
    "\n",
    "When designing VI and PI algorithms for **continuous** state and/or action spaces, all of these problems can be addressed with **approximation**, which, when applied to the DP methods (such as VI and PI) is known as **Approximate Dynamic Programming**.\n",
    "\n",
    "### Goal of this homework\n",
    "\n",
    "The purpose of this assignment is to learn about and practice applying approximation methods to continuous space environments, specifically ENDI from Rcognita.\n",
    "\n",
    "### Components\n",
    "\n",
    "* **Section 1**: Concept Review\n",
    "* **Section 2**: Approximate Dynamic Programming\n",
    "    * Exercise 1 - Linear Function Approximation\n",
    "        * Problem 1.1 - 15 points\n",
    "\n",
    "Total points: 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\">Imports and Autograder</h2>\n",
    "\n",
    "***\n",
    "Take care of imports early on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rcognita import EndiSystem, EndiControllerBase, Simulation, AnswerTracker\n",
    "from IPython.display import HTML, clear_output\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Auto-grading</font>\n",
    "Run this cell to track your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADING DO NOT MODIFY\n",
    "hw2_answers = AnswerTracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\">Section 1 - Concept Review</h2>\n",
    "\n",
    "***\n",
    "\n",
    "The following concepts will help you in completing this assignment and furthering your understanding of common taxonomy in the field of RL.\n",
    "\n",
    "### Dynamic Programming vs Reinforcement Learning\n",
    "\n",
    "Dynamic programming refers to a class of optimization methods that solve problems through recursion and aggregation, or more formally by \"by combining solutions from their subproblems\" <sup>[1]</sup>.\n",
    "<blockquote><b>DP algorithms</b> require a model of the MDP, including the transition dynamics\n",
    "and the reward function, to find an optimal policy (Bertsekas, 2007; Powell, 2007).\n",
    "Usually, they do not require an analytical expression of the\n",
    "dynamics. Instead, given a state and an action, the model is only required to generate a next state and the corresponding reward. Constructing such a generative model is often easier than deriving an analytical expression of the dynamics, especially when the dynamics are stochastic.<sup>[2]</sup></blockquote>\n",
    "\n",
    "In contrast, in reinforcement learning algorithms, the underlying model of the environment is unknown:\n",
    "<blockquote><b>RL algorithms</b> are model-free (Bertsekas and Tsitsiklis, 1996; Sutton and Barto, 1998), which makes them useful when a model is difficult or costly to construct. RL algorithms use data obtained from the process, in the form of a set of samples, a set of process trajectories, or a single trajectory. So, RL can be seen as model-free, sample- based or trajectory-based DP, and DP can be seen as model-based RL. While DP algorithms can use the model to obtain any number of sample transitions from any state-action pair, RL algorithms must work with the limited data that can be obtained from the process ‚Äì a greater challenge. Note that some RL algorithms build a model from the data; we call these algorithms ‚Äúmodel-learning.‚Äù<sup>[2]</sup></blockquote>\n",
    "\n",
    "### Offline vs Online\n",
    "\n",
    "From [2]:\n",
    "> * Offline RL methods are applicable if data can be obtained in advance. \n",
    "> * Online RL algorithms learn a solution by interacting with the system, and can therefore be applied even when data is not available in advance. For instance, intelligent agents are often placed in environments that are not fully known beforehand, which makes it impossible to obtain data in advance.\n",
    "\n",
    "### Deterministic vs Stochastic\n",
    "\n",
    "\n",
    "* **Deterministic**\n",
    "    * > A deterministic MDP is defined by the state space $X$ of the process, the action space $U$ of the controller, the transition function $f$ of the process (which describes how the state changes as a result of control actions), and the reward function $\\rho$ (which evaluates the immediate control performance). <sup>[2]</sup>\n",
    "* **Stochastic**\n",
    "    * > In a stochastic MDP, the next state is not deterministically given by the current state and action. Instead, the next state is a random variable, and the current state and action give the probability density of this random variable. <sup>[2]</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\">Section 2 - Approximate Dynamic Programming</h2>\n",
    "\n",
    "***\n",
    "\n",
    "From our previous lectures, let us recall the Q-function:\n",
    "\n",
    "$$Q^{\\pi}(s, a)=E_{\\pi}\\left[\\sum_{t=0}^{\\infty} \\gamma^{t} r_{t} \\mid s_{0}=s, a_{0}=a\\right]$$\n",
    "\n",
    "... And in expanded form (for finite state and action spaces):\n",
    "\n",
    "$$Q^\\pi{(s,a)} = \\sum_{s^\\prime\\in\\text{S}} P{(s^\\prime|s,a)} \\left[R(s,a,s^\\prime) + \\gamma \\sum_{a^\\prime\\in\\text{A}} \\pi{(a^\\prime|s^\\prime)} Q^\\pi{(s^\\prime,a^\\prime)}\\right]$$\n",
    "\n",
    "\n",
    "... Which can also be represented in terms of state-value:\n",
    "\n",
    "$$Q^{\\pi}(s, a)=\\sum_{s^{\\prime} \\in \\mathcal{S}} P\\left(s^{\\prime} \\mid s, a\\right) \\left[R\\left(s, a, s^{\\prime}\\right)+\\gamma V^{\\pi}\\left(s^{\\prime}\\right)\\right]$$\n",
    "\n",
    "This Q-function is a polynomial of $|S|$ (cardinality), which is projected recursively over a trajectory that, even in the case of a substantially large **finite** state-space, would be computationally infeasible to solve from an iteration-time perspective (as well as being too costly from a memory perspective).\n",
    "\n",
    "The question is, is there an **approximate representation** of $Q(s,a)$ that has a sufficiently small number of parameters (much less than $|S|$)? \n",
    "\n",
    "A simple, linear parametric approximation that works well in practice is the following:\n",
    "\n",
    "$$Q^{\\pi}(s, a)=\\phi(s, a)^{\\top} \\boldsymbol{\\theta}$$\n",
    "\n",
    "Where:\n",
    "* $\\phi(s, a) \\in \\mathbb{R}^{n}$\n",
    "* $\\boldsymbol{\\theta} \\in \\mathbb{R}^{n}$\n",
    "\n",
    "A word about notation:\n",
    "* $\\phi$ is the feature **function**: $\\phi : S \\times A \\rightarrow \\mathbb{R}^{n}$\n",
    "    * \"$\\phi$ maps each state-action pair to a vector of feature values\" <sup>[1]</sup>\n",
    "* $\\phi(s, a)$ is the feature **vector** of $s$ and $a$\n",
    "* $\\phi_i{(s, a)}$ denotes an feature **value** (aka simply feature) of the feature vector for state $s$ and action $a$\n",
    "* $\\theta$ is the weight vector which denotes the contribution of each feature to Q\n",
    "\n",
    "Note:\n",
    "* $\\phi$ can also take only $s$ as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Exercise 1 - Linear Function Approximation</font>\n",
    "\n",
    "To learn and understand value-function **approximation** (specifically Q-function approximation), we will be implementing an algorithm in Rcognita entitled **Trajectory Based Value Iteration Least Squares** (TBVILS) <sup>[1]</sup>:\n",
    "\n",
    "<img src=\"tbvils.png\" width=70% height=70% />\n",
    "\n",
    "### How does it work\n",
    "\n",
    "#### üí° Line 6\n",
    "\n",
    "In line 6, the buffers (of size $\\beta$) are updated with the current state and action.\n",
    "\n",
    "#### üí° Line 7\n",
    "\n",
    "On line 7 we update the weights of Q-function. This is done by minimizing the cost function known as temporal error (aka delta, $\\delta$) with respect to parameters $\\theta$:\n",
    "\n",
    "$$\\delta = (Q^{+}(s, a) - Q(s, a))^{2}$$\n",
    "\n",
    "Where (‚ùóin the case of VI):\n",
    "\n",
    "* **Approximate Q**: $\\hspace{1em} Q(s, a) = W_{j+1}^{T} \\phi\\left(x_{k}\\right)$</font>\n",
    "* **Target Q**: $\\hspace{1em} Q^{+}(s, a) = r\\left(x_{k}, h_{j}\\left(x_{k}\\right)\\right)+W_{j}^{T} \\gamma \\phi\\left(x_{k+1}\\right)$</font>\n",
    "\n",
    "Pay close attention to the differences in $W$ and $x$ above.\n",
    "\n",
    "Thus, for value iteration, for a given time-step, temporal error has the following form <sup>[3]</sup>:\n",
    "\n",
    "$$e_{k}= \\big(r\\left(x_{k}, h_{j}\\left(x_{k}\\right)\\right)+W_{j}^{T} \\gamma \\phi\\left(x_{k+1}\\right) - W_{j+1}^{T} \\phi\\left(x_{k}\\right)\\big)^2$$\n",
    "\n",
    "The task of optimization is to minimize $e_k$ to 0 by adjusting the weights $W$:\n",
    "\n",
    "$$0 = \\big(r\\left(x_{k}, h_{j}\\left(x_{k}\\right)\\right)+W_{j}^{T} \\gamma \\phi\\left(x_{k+1}\\right) - W_{j+1}^{T} \\phi\\left(x_{k}\\right)\\big)^2$$\n",
    "\n",
    "**Side-note**:\n",
    "* In policy iteration, the temporal difference equation looks differently:\n",
    "$$e_{k}= \\big(r\\left(x_{k}, h_{j}\\left(x_{k}\\right)\\right)+W_{j}^{T} \\gamma \\phi\\left(x_{k}\\right) - W_{j}^{T} \\phi\\left(x_{k+1}\\right)\\big)^2$$\n",
    "\n",
    "#### üí° Line 8:\n",
    "\n",
    "This phase is very similar to that of Q-function update, except we are minimizing the $V(s)$ function below with respect to policy weights $\\pi_{W}$.\n",
    "\n",
    "During the policy update phase - the `policy` method in the code performs the following tasks:\n",
    "1. It takes the current state $s$ and initial action $a$ and generates a trajectory of predicted states over the horizon length.\n",
    "2. It then calculates the **sum of discounted rewards** over this trajectory:\n",
    "\n",
    "$$V_{h}\\left(x_{k}\\right)=\\sum_{i=k}^{\\infty} \\gamma^{i-k} r\\left(x_{i}, u_{i}\\right) $$\n",
    "3. Steps 1 and 2 are repeated until cost from step 2 is **minimized** (see next section)\n",
    "\n",
    "The minimization function that we use is scipy's `minimize`, which is responsible for executing step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you get started: notation details\n",
    "\n",
    "Rcognita is designed to be used as a framework for DP, RL, *and* control systems. Therefore, we use a variety of notation that is common to these areas.\n",
    "\n",
    "For example, instead of the following:\n",
    "\n",
    "$$Q^{\\pi}(s, a)=\\phi(s, a)^{\\top} \\boldsymbol{\\theta}$$\n",
    "\n",
    "In our code you will see the Q-function represented as <sup>[3]</sup>:\n",
    "\n",
    "$$Q_{h}(x, u)=W^{T} \\phi(x, u)$$\n",
    "\n",
    "Where <sup>[3]</sup>:\n",
    "* $h$ is a **policy** (aka $\\pi$)\n",
    "* $x$ is the **state**\n",
    "* $y$ is the **output** of a system (which is the same thing as $x$ in our code)\n",
    "* $u$ is the **control** (aka action)\n",
    "* $W$ is the weight vector (aka $\\theta$)\n",
    "\n",
    "#### Other related notation and the objective function :\n",
    "\n",
    "* $\\dot{x} = f(x,u)$ - the system dynamics (change in system's state)\n",
    "* $x_k \\in R^n$ - state vector (where $k$ is a time step)\n",
    "* $u_k = h(x_k)$ - control function (a.k.a. policy function)\n",
    "    * where $u_k \\in R^m$\n",
    "* $r(x_k, u_k)$ - utility function, aka instantaneous cost or reward function\n",
    "\n",
    "And finally:\n",
    "\n",
    "$$V_{h}\\left(x_{k}\\right)=\\sum_{i=k}^{\\infty} \\gamma^{i-k} r\\left(x_{i}, u_{i}\\right)$$\n",
    "\n",
    "While in RL this is known as the *state-value function* with respect to a policy $h$, in dynamical systems and DP, \"this is known as the **cost-to-go** and is a sum of discounted future costs from\n",
    "the current time k into the infinite horizon future\" <sup>[3]</sup>. Other names for $V(s)$ include **cost** and **value**.\n",
    "\n",
    "#### ‚ùó In the context of control theory, dynamical systems, and this assignment -- <font color=\"red\">the value function is minimized, not maximized</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Problem 1</font>\n",
    "\n",
    "Let's apply the TBVILS algorithm to the ENDI environment from Rcognita. Here is the algorithm again for convenience <sup>[1]</sup>:\n",
    "\n",
    "<img src=\"tbvils.png\" width=70% height=70% />\n",
    "\n",
    "### Variables in Rcognita\n",
    "\n",
    "Recall that in the ENDI environment of Rcognita:\n",
    "The environment has the following 5 characteristics:\n",
    "* **x ($x_c$)** = x-coordinate (m)\n",
    "* **y ($y_c$)** = y-coordinate (m)\n",
    "* **alpha ($\\alpha$)** = turning angle (rad)\n",
    "* **upsilon ($\\upsilon$)** = velocity (m/s)\n",
    "* **omega ($\\omega$)** = revolution speed (rad/s) (aka turning speed)\n",
    "\n",
    "For a given time-step, $t$:\n",
    "* Action or control input is given by: $\\hspace{3mm}a_t = (F, M)$\n",
    "* Environment is given by: $\\hspace{3mm}s_t = (x_c, y_c, \\alpha, \\upsilon, \\omega)$\n",
    "\n",
    "Thus in the ENDI environment, $\\phi(s,a)$ would be:\n",
    "* $\\phi(s_t, a_t) = (x_c, y_c, \\alpha, \\upsilon, \\omega, F, M)$\n",
    "\n",
    "Usually $\\phi$ takes a quadratic form, in which $\\phi : (S \\times A)^2 \\rightarrow \\mathbb{R}^{n}$\n",
    "\n",
    "**Note**: note that $\\phi$ can also take *only* state (in the case of state-value function).\n",
    "\n",
    "#### üéØ Task: implement the TBVILS algorithm in the code below by filling in the lines specified by comments\n",
    "Remember the key functions from above and implement them:\n",
    "\n",
    "Hints:\n",
    "* Work method by method, filling in the code where the comments specify.\n",
    "* When working on the `value_function`, note the:\n",
    "    * *temporal difference* equation.\n",
    "    * V(s) (expected return over a trajectory from a given state $s$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TBVILS(EndiControllerBase):\n",
    "    \"\"\" Implementation of Trajectory Based Value Iteration with LS minimization\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, system, horizon_length=10, **kwargs):\n",
    "        super(TBVILS, self).__init__(system, **kwargs)\n",
    "        self.ctrl_mode = 3\n",
    "        self.x_buffer = self.y_buffer # renaming y to x to stick to common notation\n",
    "        self.horizon_length = horizon_length\n",
    "        self.gamma = 0.95\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        # control bounds tiled over horizon_length\n",
    "        self.u_min = np.tile(self.min_bounds, self.horizon_length)\n",
    "        self.u_max = np.tile(self.max_bounds, self.horizon_length)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\" initialize weights for parameter vector `W` \"\"\"\n",
    "\n",
    "        num_weights = int(self.dim_state + self.dim_input)\n",
    "\n",
    "        self.W = np.random.rand(num_weights)\n",
    "        self.w_min = np.zeros(num_weights)\n",
    "        self.w_max = 1e3 * np.ones(num_weights)\n",
    "    \n",
    "    def _update_buffers(self, u, x):\n",
    "        \"\"\" update x and u buffers on each call of compute_action\n",
    "\n",
    "        Args:\n",
    "\n",
    "            u : float vector\n",
    "                * control (action)\n",
    "\n",
    "            x : float vector\n",
    "                * state\n",
    "\n",
    "        \"\"\"\n",
    "        self.u_buffer = np.vstack([self.u_buffer, u])[-self.buffer_size:, :]\n",
    "        self.x_buffer = np.vstack([self.x_buffer, x])[-self.buffer_size:, :]\n",
    "        \n",
    "    def compute_action(self, t, x):\n",
    "        \"\"\" compute action for time step\n",
    "\n",
    "        Args:\n",
    "\n",
    "            t : float\n",
    "                * time step - current time step\n",
    "            \n",
    "            x : float vector\n",
    "                * state\n",
    "\n",
    "        Returns:\n",
    "            u : vector\n",
    "                * new action/control\n",
    "\n",
    "        \"\"\"\n",
    "        time_since_last_action = t - self.ctrl_clock\n",
    "\n",
    "        if time_since_last_action >= self.sample_time:\n",
    "            # Update controller's internal clock\n",
    "            self.ctrl_clock = t\n",
    "\n",
    "            ### YOUR SOLUTION BELOW\n",
    "            # Line 6: update buffers (call method above)\n",
    "            self._update_buffers(self.u_curr, x)\n",
    "            \n",
    "            # Line 7: update Q-function (call weight_update method)\n",
    "            self.W = self._weight_update(self.W, self.u_buffer, self.x_buffer)\n",
    "            \n",
    "            # Line 9: update policy function (call policy_method)\n",
    "            self.u_curr = self._policy(x, self.W)\n",
    "            \n",
    "            return self.u_curr\n",
    "            ### YOUR SOLUTION ABOVE\n",
    "\n",
    "        else:\n",
    "            return self.u_curr\n",
    "\n",
    "    def _policy(self, x, W):\n",
    "        \"\"\" calculate next action for state\n",
    "\n",
    "        Args:\n",
    "\n",
    "            x : float vector\n",
    "\n",
    "        Returns:\n",
    "        \n",
    "            u : vector\n",
    "                * new action/control\n",
    "\n",
    "        \"\"\"\n",
    "        # define solver options\n",
    "        options = {'maxiter': 200, 'disp': False, 'ftol': 1e-7}\n",
    "        bounds = sp.optimize.Bounds(self.u_min, self.u_max, keep_feasible=True)\n",
    "\n",
    "        # tile current action across buffer size to make trajectory\n",
    "        u_trajectory = np.tile(self.u_curr, self.horizon_length)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Minimize cost-over-trajectory with respect to actions. Returns a trajectory of actions.\n",
    "        You'll need to study how this works by reading the documentation. The variable `u_trajectory` \n",
    "        serves as an initial input of actions used by `minimize` to minimize \n",
    "        the cost by updating parameters.\n",
    "        \"\"\"\n",
    "        \n",
    "        U_new = minimize(lambda U: self._cost_over_traj(U, W, x), u_trajectory,\n",
    "                     method='SLSQP',\n",
    "                     tol=1e-7,\n",
    "                     bounds=bounds,\n",
    "                     options=options).x\n",
    "\n",
    "        # output first action of new action (trajectory)\n",
    "        first_u = U_new[:self.dim_input]\n",
    "\n",
    "        return first_u\n",
    "\n",
    "    def _cost_over_traj(self, u, w, x):\n",
    "        \"\"\" generate trajectory of steps and calculate cost over the trajectory\n",
    "\n",
    "        Description: given initial action (u) and observtion (x), create a trajectory of predicted steps/states, where the number of predictions == horizon_length. Then, calculate the discounted cost of this trajectory with the Q-function.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            u : float vector\n",
    "                * control/action\n",
    "            \n",
    "            w : float vector\n",
    "                * Q-function parameters\n",
    "            \n",
    "            x : float vector\n",
    "                * state\n",
    "\n",
    "        Returns: \n",
    "\n",
    "            trajectory_q_cost : float\n",
    "\n",
    "        \"\"\"\n",
    "        u_trajectory = np.reshape(u, (self.horizon_length, self.dim_input))\n",
    "        x_trajectory = np.zeros([self.horizon_length, self.dim_output])\n",
    "        x_trajectory[0, :] = x\n",
    "\n",
    "        for k in range(1, self.horizon_length):\n",
    "            x = x + self.step_size * self.sys_dynamics(None, x, u_trajectory[k - 1, :], self.m, self.I, self.dim_state, self.is_disturb)\n",
    "\n",
    "            x_trajectory[k, :] = x\n",
    "\n",
    "        ### YOUR SOLUTION BELOW\n",
    "        # calculate cost of trajectory by calling the value function. `calculate_td` should be false.\n",
    "        traj_q_cost = self._value_function(w, u_trajectory, x_trajectory, self.horizon_length, calculate_td=False)\n",
    "        ### YOUR SOLUTION ABOVE\n",
    "\n",
    "        return traj_q_cost\n",
    "\n",
    "    def _weight_update(self, Winit, u_buffer, x_buffer):\n",
    "        \"\"\" update weights for Q-function.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            Winit : float vector\n",
    "                * initial weights for solver to start minimizing from\n",
    "\n",
    "            u_buffer : 2D float array\n",
    "                * controls buffer\n",
    "\n",
    "            x_buffer : 2D float array\n",
    "                * state buffer\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            W_new - updated weights\n",
    "\n",
    "        \"\"\"\n",
    "        ### YOUR SOLUTION BELOW\n",
    "        # your solution should look very similar to the policy update.\n",
    "        options = {'maxiter': 200, 'disp': False, 'ftol': 1e-7}\n",
    "        bounds = sp.optimize.Bounds(self.w_min, self.w_max, keep_feasible=True)\n",
    "\n",
    "        W_new = minimize(lambda W: self._value_function(W, u_buffer, x_buffer, self.horizon_length, calculate_td=True), \n",
    "                     Winit,\n",
    "                     method='SLSQP',\n",
    "                     tol=1e-7,\n",
    "                     bounds=bounds,\n",
    "                     options=options).x\n",
    "\n",
    "        return W_new\n",
    "        ### YOUR SOLUTION ABOVE\n",
    "\n",
    "    def _value_function(self, W, u_container, x_container, length, calculate_td=False):\n",
    "        \"\"\" Q-function\n",
    "\n",
    "        Args:\n",
    "\n",
    "            W : float vector\n",
    "                * Q-function parameters\n",
    "\n",
    "            u_container : 2D float array\n",
    "                * buffer or trajectory of control inputs\n",
    "\n",
    "            x_container : 2D float array\n",
    "                * buffer or trajectory of observations\n",
    "            \n",
    "            calculate_td : boolean\n",
    "                * calculcate V(S) or temporal difference?\n",
    "\n",
    "        Returns:\n",
    "            J : float\n",
    "                * cost\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        ### YOUR SOLUTION BELOW\n",
    "\n",
    "        J = 0\n",
    "        i = length\n",
    "\n",
    "        for k in range(1, length):\n",
    "            x = x_container[k - 1, :]\n",
    "            u = u_container[k - 1, :]\n",
    "            x_next = x_container[k, :]\n",
    "            u_next = u_container[k, :]\n",
    "\n",
    "            if calculate_td:\n",
    "                # calculate temporal difference (don't forget to increment J)\n",
    "                phi_curr = self._phi(x,u)\n",
    "                phi_next = self._phi(x_next,u_next)\n",
    "                \n",
    "                aprox = np.dot(W.T, phi_curr)\n",
    "                target = self.running_cost(x, u) + np.dot((self.W.T*self.gamma), phi_next)\n",
    "                J += (target - aprox)**2\n",
    "            else:\n",
    "                # calculate cost over trajectory (don't forget to increment J)\n",
    "                J += self.gamma**(k-i) * self.running_cost(x, u)\n",
    "            \n",
    "        ### YOUR SOLUTION ABOVE\n",
    "        return J\n",
    "\n",
    "    def _phi(self, x, u=None):\n",
    "        \"\"\" Feature vector used in approximating Q\n",
    "\n",
    "        Args:\n",
    "\n",
    "            x : float vector\n",
    "                * state\n",
    "\n",
    "            u : float vector\n",
    "                * controls\n",
    "\n",
    "        returns:\n",
    "            chi : vector\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        ### YOUR SOLUTION BELOW\n",
    "        if u is not None:\n",
    "            chi = np.concatenate([x, u])\n",
    "        else:\n",
    "            chi = x\n",
    "        ### YOUR SOLUTION ABOVE\n",
    "\n",
    "        return chi**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation\n",
    "\n",
    "Run the cell below to conduct training.\n",
    "* Note if the table rows overrun onto other rows, it's because of the width of jupyter notebook page. If you run this from terminal, the table appears correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........Run 2 done........\n",
      "Total runs for each controller: 2\n",
      "Statistics for controller 1:\n",
      "            - Mean of running cost: 238.86\n",
      "            - Mean of velocity: -0.81\n",
      "            - SD of running cost: 357.12\n",
      "            - SD of velocity: 0.83\n",
      "            - SD of turning angle: 238.86\n",
      "            - Final L2-norm: 0.021\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "# create system\n",
    "sys = EndiSystem(initial_x=7, initial_y=7)\n",
    "\n",
    "# create agent\n",
    "agent = TBVILS(sys, sample_time=0.3, t1=17)\n",
    "\n",
    "# create sim\n",
    "sim = Simulation(sys, agent)\n",
    "\n",
    "sim.run_simulation(n_runs=2, \n",
    "                is_visualization=False, \n",
    "                close_plt_on_finish=False, \n",
    "                show_annotations=True, \n",
    "                print_summary_stats=False, \n",
    "                print_statistics_at_step=True,\n",
    "                print_inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you choose to run the visual training option below, you can print summary statistics with `sim.print_sim_summary_stats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ‚â• 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:,\" width=\"0\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # uncomment to run visual training option\n",
    "%matplotlib notebook\n",
    "HTML(sim.run_simulation(n_runs=2, fig_width=7, fig_height=7, show_annotations=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Auto-grading</font>\n",
    "Run this cell to track your answers and to save your answer for problem 1.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADING DO NOT MODIFY\n",
    "statistics, = sim.final_statistics\n",
    "\n",
    "hw2_answers.record('problem_1-2', {'mean_rc': statistics[0],\n",
    "    'mean_velocity': statistics[1], \n",
    "    'sd_rc': statistics[2],\n",
    "    'sd_velocity': statistics[3],\n",
    "    'sd_alpha': statistics[4],\n",
    "    'l2_norm': statistics[5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238.86, -0.81, 357.12, 0.83, 238.86, 0.021)\n"
     ]
    }
   ],
   "source": [
    "print(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations\n",
    "\n",
    "Linear approximation is a fundamental method by which real-life RL problems are solved. This assignment showed you the basis of how they work and what their mathematical forms are. Please get comfortable with the basics of linear algebra, matrix calculus, and Python as we proceed to more diverse challenges in the coming assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Auto-grading: Submit your answers</font>\n",
    "Enter your first and last name in the cell below and then run it to save your answers for this lab to a JSON file. The file is saved to the same directory as this notebook. After the file is created, upload the JSON file to the assignment page on Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problem_1-2': {'mean_rc': 238.86, 'mean_velocity': -0.81, 'sd_rc': 357.12, 'sd_velocity': 0.83, 'sd_alpha': 238.86, 'l2_norm': 0.021}}\n"
     ]
    }
   ],
   "source": [
    "hw2_answers.print_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_name = \"hw_2\"\n",
    "first_name = \"Nikita\" # Use proper capitalization\n",
    "last_name = \"Mikhailovskiy\" # Use proper capitalization\n",
    "\n",
    "hw2_answers.save_to_json(assignment_name, first_name, last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions?\n",
    "\n",
    "Reach out to your instructors on Piazza.\n",
    "\n",
    "### Sources\n",
    "\n",
    "***\n",
    "\n",
    "<sup>[1]</sup> Geramifard, A., Walsh, T., Tellex, S., Chowdhary, G., Roy, N., & How, J.P. (2013). A Tutorial on Linear Function Approximators for Dynamic Programming and Reinforcement Learning. Found. Trends Mach. Learn., 6, 375-451.\n",
    "\n",
    "<sup>[2]</sup> Busoniu, L., Babu≈°ka, R., Schutter, B.D., & Ernst, D. (2010). Reinforcement Learning and Dynamic Programming Using Function Approximators.\n",
    "\n",
    "<sup>[3]</sup> Lewis, F., & Vrabie, D. (2009). Reinforcement learning and adaptive dynamic programming for feedback control. IEEE Circuits and Systems Magazine, 9, 32-50."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
